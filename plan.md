# Memory Usage Analysis for the `log_message` Action in WFL

## Root Causes of Excessive Memory Usage

* **Closure Reference Cycle in Action Definition:** Defining the `log_message` action was creating a reference cycle between the function and its defining environment. In the WFL interpreter, user-defined actions (functions) were stored in the environment as an `Rc<FunctionValue>`, and the function captured a pointer to its parent environment. Originally, both were strong references, forming a cycle that the Rust garbage collector couldn’t free. This meant that even after the function’s use, its environment (and all enclosed data) stayed in memory, leaking resources and causing ballooning memory usage simply by defining the action.

* **Inefficient Parsing and AST Construction:** The WFL parser is consuming a lot of memory when parsing complex expressions and long scripts like `test.wfl`. Heap profiling revealed that the expression parsing routines (e.g. `parse_primary_expression` and `parse_binary_expression`) are responsible for a **disproportionate number of allocations**. Every literal, operator, or `with` concatenation in `log_message` creates new AST nodes and strings, often cloning data repeatedly. The parser grows vectors (like the list of statements or expression tokens) incrementally without sufficient pre-allocation, leading to many small reallocations. In a large script, these inefficiencies accumulate to extreme levels – for example, the full `nexus.wfl` test peaked at \~10.7 GB of memory and over 152 million allocations in profiling. In short, parsing the `log_message` action (and the script around it) generates excessive temporary objects and AST nodes, stressing memory.

* **Costly File Read-Modify-Write in `log_message`:** The implementation of `log_message` performs file I/O in a very memory-intensive way. Each time `log_message` is called, it **reads the entire `nexus.log` file content into memory**, appends a line, then **writes the entire content back** to the file. The interpreter’s I/O client opens the file and uses `read_to_string` to load it fully into a Rust `String`, and the write operation seeks to the start of the file, truncates it to zero, then writes out the new full content string. This approach causes **O(n)** memory use per call (proportional to the file size) and can lead to quadratic growth in work: as the log grows, each new message requires reading and reallocating a bigger and bigger string. If `log_message` runs in a loop, memory usage spikes dramatically because each iteration allocates a large buffer for the full log content and an equally large buffer for the updated content. Additionally, keeping the log file open (`logHandle`) while also opening it again for reading (as the code does) can cause errors or extra overhead (the interpreter had to clone file handles and manage them in a map). In summary, the current **read-modify-write pattern is very inefficient**, using excessive memory to repeatedly copy growing logfile text.

* **Unbounded Loops or Recursive Calls:** While not a direct issue in `log_message` itself, the interpreter had to handle loops and recursion carefully to avoid runaway memory usage. In earlier versions, a lack of limits meant a long-running loop or deep recursion could consume memory without bound. For example, without safeguards a recursive action could keep pushing new call frames and never release them, or a loop could keep growing data structures. The developers identified that the debug call stack (`Vec<CallFrame>`) could **balloon in size over long or deeply recursive runs** if frames weren’t popped or cleared promptly. Similarly, creating large data (huge lists, strings, etc.) in a loop or printing large debug traces could fill memory. The latest code mitigates this by capping loop iterations (e.g. a `count` loop is limited to 10,000 iterations by default) and by ensuring call frames are popped on function return. These measures prevent infinite or extremely large loops from exhausting memory. However, if such limits or pops failed (for instance, an uncapped loop or a recursion that doesn’t unwind), memory usage would spike due to continuously growing vectors or lingering allocations.

## Recommendations and Fixes

* **Break Reference Cycles in Functions:** The most critical fix is to eliminate the strong reference cycle between an action and its environment. This has been addressed by storing a **weak reference** to the defining environment in each `FunctionValue`. The `log_message` action now captures its environment via `Weak<RefCell<Environment>>` instead of `Rc`. In code, this means using `Rc::downgrade(&env)` when constructing a FunctionValue. With this change, defining an action no longer leaks memory – once the function and environment go out of scope, Rust can clean them up (the environment’s strong reference count isn’t kept artificially high by the function itself). **Ensure all similar back-references use `Weak`.** (The parent environment link was already using Weak, and now closures do as well.) This prevents the kind of leak that was triggered by merely defining `log_message` in the global scope.

* **Optimize Parsing and AST Handling:** To address the heavy memory churn during parsing, the WFL compiler/interpreter should be optimized for fewer allocations and clones. Several strategies can help:

  * **Preallocate Vectors:** Reserve sufficient capacity for the AST `Program` and statement lists when parsing a file. The current parser grows vectors gradually; instead, use heuristics or file size to reserve memory up front (e.g. the parser already does a rough `tokens.count()/5` reserve, but this could be tuned to reduce reallocations).
  * **Avoid Excessive Cloning:** When building AST nodes, avoid cloning strings or tokens more than necessary. The lexer already interns identifier substrings to reuse strings; similarly, the parser could reuse `String` allocations for repeated identifiers or literals. Ensure that intermediate results (like multi-word identifier assembly or the chain of `"with"` concatenations) don’t create lots of throwaway Strings.
  * **Use Iterative Parsing or Pools:** The `parse_primary_expression` and `parse_binary_expression` routines should be reviewed for recursion or repeated passes. Converting deeply recursive parsing logic into an iterative loop can lower function-call overhead and allocations. Using an object pool or arena allocator for AST nodes could also cut down on per-node heap overhead – all nodes could be freed in one batch when the parse is done, rather than individually on the heap.
  * These improvements would significantly reduce the \~152 million allocations seen in profiling. Fewer and more efficient allocations mean lower peak memory usage during script loading. In practice, after these changes, the `test.wfl` (Nexus) script should parse with a fraction of the memory it formerly required.

* **Streamline File I/O in `log_message`:** The logging approach should be reworked to avoid reading the entire file on each message append. There are a few possible fixes:

  * **Append Instead of Read/Rewrite:** Open the log file in **append mode** once, and simply write new log lines to the end as they come. This eliminates the need to ever read the full file content into memory. In Rust’s terms, one could open the file with `create(true), append(true)` options and on each `log_message` call just do a `write_all(new_line)` on the file handle. This approach uses constant memory per write (just the size of the new log entry, which is tiny) instead of scaling with the file size. It also avoids the costly truncate step. Currently, the code always seeks to start and truncates before writing, which is unnecessary if we only want to add new content.
  * **Keep a Single File Handle:** Rather than repeatedly calling `open_file` for reading (and then closing), maintain the file handle opened at the start (`logHandle`) and use it for both reading and writing as needed. Ideally, **avoid opening the same file twice** concurrently. In the current implementation, `open file at "nexus.log" as logHandle` opens the file (read/write) and stores the handle ID in `logHandle`, but `log_message` then does another `open file at "nexus.log" and read content...` which tries to open a second handle for the same file. This was both memory-inefficient and logically problematic (the code had to clone file handles and would error if the file was already open). Instead, use the existing `logHandle`: for example, provide a way to **read from an already-open handle**. The interpreter could have a built-in action or syntax like `read content from logHandle` to get the current content if truly needed. In short, avoid duplicating open file handles and reuse them to save overhead.
  * **On-demand or Buffered Reading:** If reading the file content is necessary (e.g. to support other operations), consider reading it in a streaming or buffered fashion. For example, to get the current content length or last lines, you don’t need to load the entire file into a `String`. Using a buffered reader to seek to the end or maintain a rolling buffer of the log could cut down memory usage. However, if we implement true append logging as above, we rarely need to read the log file at runtime at all (unless another part of the script needs the log content).
  * Together, these changes mitigate the O(n²) memory growth pattern. By writing new log entries directly, `log_message` will use constant memory and time per call. This is a much more scalable design for logging, preventing the spike in memory consumption observed with the read-modify-write approach.

* **Release Resources Promptly:** Ensure that resources and data structures are freed as soon as they are no longer needed. In the interpreter code:

  * **Close File Handles:** After finishing the test or when `logHandle` is no longer needed, explicitly close the file. The interpreter’s `IoClient` provides a `close_file` method to remove the handle from its internal map. Not closing means the `file_handles` map and the underlying OS handle stay alive, which is a minor memory and descriptor leak. In long-running sessions or when opening many files, this could accumulate. In our case, calling `close_file(logHandle)` at the end of the script (or when the program exits) will free that entry.
  * **Function Call Stack Cleanup:** The call stack frames should continue to be popped on every function return – the current implementation does this properly with `.pop()` in both normal returns and error paths. We should also clear any lingering call-stack or debug info after execution. The interpreter already resets the call stack at the start of a new run; similarly, after the script completes, no debug trace should hold references to large data (for example, if an error occurred that captured local variables, ensure those are dropped or truncated). This defensive practice avoids residual memory usage from one run affecting the next.
  * **Loop Variables Environment:** In long loops (like a `count` loop), the interpreter creates a child environment for loop variables. That environment should be dropped when the loop concludes. The current code uses a single `loop_env` for the whole loop and lets it go out of scope, which is good. We just need to be mindful that no references to it linger. Adopting Rust’s ownership idioms (so that when the loop finishes, the `Rc<Environment>` is dropped if nothing else holds it) suffices. This ensures memory used for loop internals is freed promptly.
  * **Limit Debug Output Sizes:** If the interpreter prints or logs large data structures (e.g. dumping the entire environment or a huge list for debugging), it should truncate this output. The memory investigation noted that printing enormous structures can allocate giant strings in memory. Imposing a reasonable size limit on debug strings or logging only summaries will prevent unexpectedly high memory usage during error reporting or verbose modes.

* **Further Improvements (Long-Term):**
  In addition to the immediate fixes above, a few architectural improvements can help WFL’s memory profile:

  * **Lazy Evaluation or Streaming**: For large data (like big text blobs or file content), consider lazy iteration or streaming rather than materializing everything in memory. For example, if WFL had to process a very large file, a streaming API would let you handle it in chunks. While not directly needed for `log_message`, this principle can keep memory flat for other use cases.
  * **Bytecode or AST Execution Efficiency**: Since the roadmap mentions a future bytecode VM, that could also alleviate some memory overhead. Bytecode execution typically uses less memory than walking a high-level AST with many allocations. In the interim, auditing the interpreter’s runtime data structures (lists, objects, etc.) to ensure they don’t hold onto memory longer than necessary will help. For instance, if large lists are created and then no longer used, the garbage collector (Rust’s drop logic in this case) should free them – make sure no lingering `Rc` or global cache prevents that.
  * **Testing and Profiling**: Finally, after applying the fixes for the identified issues, it’s recommended to **re-run memory profiling** (as was done with heaptrack) to verify that the leaks are gone and the usage is dramatically lower. Adding automated tests for memory (if possible) or at least running the integration tests under a memory checker can catch any regressions. This way, future changes (like new features or library additions) won’t reintroduce leaks or excessive memory usage.

By implementing these changes, the `log_message` action should no longer cause pathological memory behavior. Defining or calling the action will use only the necessary memory: the environment cycle is eliminated, parsing is more frugal with allocations, and file logging writes only incremental data instead of copying the entire log on each call. These fixes together will ensure that WFL’s interpreter runs more efficiently and can handle larger scripts without exhausting system memory.

**Sources:**

* WFL Memory Leak Analysis and Plan
* WFL Interpreter Source (environment, parser, I/O implementation)